{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2005_intro_nb_autodiff.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8AIkPXby1OXL","colab_type":"text"},"source":["# Introduction to TensorFlow\n","# Notebook - Automatic Differentiation\n","\n","*Disclosure: This notebook is an adaptation of Toronto's Neural Networks and Deep Learning Course (CSC421) tutorial material.*"]},{"cell_type":"markdown","metadata":{"id":"ESIBG6jShIN6","colab_type":"text"},"source":["## Setup of python packages\n","Google Colaboratory comes with a preinstalled Python runtime    "]},{"cell_type":"code","metadata":{"id":"SCX_7pUI6Qkn","colab_type":"code","outputId":"eebabbf4-9afc-4558-858b-7286a7614694","executionInfo":{"status":"ok","timestamp":1589096770346,"user_tz":-120,"elapsed":481,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Show used python version\n","import sys\n","print(f\"Used python version: {sys.version}\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Used python version: 3.6.9 (default, Apr 18 2020, 01:56:04) \n","[GCC 8.4.0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FfhYFqhtlHhY"},"source":["Install any python package via pip within the virtual machine provided by colab using\n","    \n","    !pip install <package>\n","\n","Note: each time the runtime is reset, you have to reinstall all required packages.\n","    "]},{"cell_type":"code","metadata":{"id":"yGfqWrZPhSvz","colab_type":"code","outputId":"b9f4c1f2-5d86-49d9-e188-a55452fcc060","executionInfo":{"status":"ok","timestamp":1589096778084,"user_tz":-120,"elapsed":4743,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Install symbolic python package\n","!pip install sympy"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy) (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zq9ob4Pvh_T-","colab_type":"code","colab":{}},"source":["# Import the installed package\n","import sympy as sp"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dhh17SsrnDFD","colab_type":"text"},"source":["## Approaches for computing derivatives\n","\n","* **Numeric differentiation:** Approximating derivatives by finite differences:\n","$$\n","\\frac{\\partial}{\\partial x_i} f(x_1, \\dots, x_N) = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_N) - f(x_1, \\dots, x_i - h, \\dots, x_N)}{2h}\n","$$\n","\n","* **Symbolic differentiation:** automatic manipulation of mathematical expressions to get derivatives\n","    - Takes a math expression (e.g. sigmoid) and returns a math expression: $$\\sigma(x) = \\frac{1}{e^{-x} + 1} \\rightarrow \\frac{d\\sigma(x)}{dx} = \\frac{e^{-x}}{(e^{-x} + 1)^2} = \\sigma(x)(1 - \\sigma(x)$$\n","    - Used in SymPy or Mathematica\n","\n"]},{"cell_type":"code","metadata":{"id":"Q0QsQz8Pg52l","colab_type":"code","outputId":"64eca2e1-4c00-4aa4-a77a-dd1f5a474203","executionInfo":{"status":"ok","timestamp":1589096819362,"user_tz":-120,"elapsed":495,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["# Use SymPy for symbolic differentiation\n","# E.g. sigmoid of convolution of two inputs\n","x_1, x_2, w_1, w_2, b_1 = sp.symbols('x_1, x_2, w_1, w_2, b_1', real=True)\n","g = 1 / (1 + sp.exp(-(w_1 * x_1 + w_2 * x_2 + b_1)))\n","\n","print(f'Mathematical Expression: $$g(x) = {sp.latex(g)}$$')\n","print(f'Partial Derivatives:')\n","for var in [x_1, x_2]:\n","    print(f'$$ \\\\frac{{\\\\partial g}}{{\\\\partial {str(var)} }} = {sp.latex(sp.simplify(g.diff(var)))} $$')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mathematical Expression: $$g(x) = \\frac{1}{e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1}$$\n","Partial Derivatives:\n","$$ \\frac{\\partial g}{\\partial x_1 } = \\frac{w_{1} e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}}}{\\left(e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1\\right)^{2}} $$\n","$$ \\frac{\\partial g}{\\partial x_2 } = \\frac{w_{2} e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}}}{\\left(e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1\\right)^{2}} $$\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ORKM_E5HiL9B","colab_type":"text"},"source":["If posted to a text cell, the code snippet generates the following latex expressions.\n","\n","Mathematical Expression: $$g(x) = \\frac{1}{e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1}$$\n","Partial Derivatives:\n","$$ \\frac{\\partial g}{\\partial x_1 } = \\frac{w_{1} e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}}}{\\left(e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1\\right)^{2}} $$\n","$$ \\frac{\\partial g}{\\partial x_2 } = \\frac{w_{2} e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}}}{\\left(e^{- b_{1} - w_{1} x_{1} - w_{2} x_{2}} + 1\\right)^{2}} $$"]},{"cell_type":"markdown","metadata":{"id":"l89JMdjYg4so","colab_type":"text"},"source":["* **Automatic differentiation:** Takes code that computes a function and returns code that computes the derivative of that function.\n","    - Reverse Mode AD: A method to get exact derivatives efficiently, by storing information as you go forward that you can reuse as you go backwards\n","    - The goal isn't to obtain closed-form solutions, but to be able to wirte a program that efficiently computes the derivatives (Backpropagation)"]},{"cell_type":"markdown","metadata":{"id":"q-yuzNAUnDFF","colab_type":"text"},"source":["## Autograd\n","\n","* [Autograd](https://github.com/HIPS/autograd) is a Python package for automatic differentiation.\n","* There are a lot of great [examples](https://github.com/HIPS/autograd/tree/master/examples) provided with the source code\n","\n","### What can Autograd do?\n","\n","From the Autograd Github repository:\n","\n","* Autograd can automatically differentiate native Python and Numpy code.\n","* It can handle a large subset of Python's features, including loops, conditional statements (if/else), recursion and closures\n","* It can also compute higher-order derivatives\n","* It uses reverse-mode differentiation (a.k.a. backpropagation) so it can efficiently take gradients of scalar-valued functions with respect to array-valued arguments.\n","\n","### Autograd vs Deep Learning Frameworks\n","\n","Many Deep Learning packages implement automatic differentiation using _domain-specific languages_ within Python. Older versions, such as TensorFlow 1.X, required you to _explicitly_ construct a computation graph; Autograd constructs a computation graph _implicitly_, by tracking the sequence of operations that have been performed during the execution of a program.\n","\n","Note: There is no direct GPU support for Autograd. If you're interested in automatic differentiation with support for hardware accelerators have a look at [JAX](https://github.com/google/jax). It is a successor that provides Just-in-Time compilation like PyTorch or TensorFlow. "]},{"cell_type":"markdown","metadata":{"id":"mhBNeLV4nDFF","colab_type":"text"},"source":["## Autograd Basic Usage\n","\n","Autograd wraps the NumPy package providing an almost identical API to the NumPy functionality, but performs additional bookkeeping in the background to build the computation graph."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"332e4f3e-6ed0-4a70-b3f0-24298f99c054","executionInfo":{"status":"ok","timestamp":1589096958688,"user_tz":-120,"elapsed":3336,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"id":"VHDQnF6upyog","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["# Install autograd\n","!pip install autograd"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: autograd in /usr/local/lib/python3.6/dist-packages (1.3)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from autograd) (1.18.4)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ze0vaLfPnDFH","colab_type":"code","colab":{}},"source":["# Import autograd\n","import autograd.numpy as np # Import thinly-wrapped NumPy\n","from autograd import grad   # The only function of Autograd, you need to call"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBM2h_pvnDFP","colab_type":"code","outputId":"d98ddede-60dc-4867-a9c8-45493f915b28","executionInfo":{"status":"ok","timestamp":1589097036237,"user_tz":-120,"elapsed":628,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Define a function like normal, using Python and Numpy\n","def tanh(x):\n","    y = np.exp(-x)\n","    return (1.0 - y) / (1.0 + y)\n","\n","# Create a *function* that computes the gradient of tanh\n","grad_tanh = grad(tanh)  # autograd.grad takes a function as input\n","\n","# Evaluate the gradient at x = 1.0\n","print(f'Autograd gradient:  {grad_tanh(1.0)}')\n","\n","# Compare to numeric gradient computed using finite differences\n","h = 0.0001\n","print(f'Finite differences: {(tanh(1.0001) - tanh(0.9999)) / (2*h)}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Autograd gradient:  0.39322386648296376\n","Finite differences: 0.39322386636453377\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X0ZItxQUnDFT","colab_type":"text"},"source":["## Autograd vs Manual Gradients via Staged Computation\n","\n","In this example, we will see how the computation of a function can be written as a composition of simpler functions. This provides a scalable strategy for computing gradients using the chain rule.\n","\n","Say we want to write a function to compute the gradient of the *sigmoid function*:\n","$$\n","\\sigma(x) = \\frac{1}{e^{-x} + 1}\n","$$\n","We can write $\\sigma(x)$ as a composition of several elementary functions, as $\\sigma(x) = s(c(b(a(x))))$, where:\n","\n","$$\n","a(x) = -x\n","$$\n","\n","$$\n","b(a) = e^a\n","$$\n","\n","$$\n","c(b) = 1 + b\n","$$\n","\n","$$\n","s(c) = \\frac{1}{c}\n","$$\n","\n","Here, we have \"staged\" the computation such that it contains several intermediate variables, each of which are basic expressions for which we can easily compute the local gradients.\n","\n","The input to this function is $x$, and the final output is represented by $s$. We wish compute the gradient of $d$ with respect to $x$, $\\frac{\\partial s}{\\partial x}$. In order to make use of our intermediate computations, we can use the chain rule as follows:\n","$$\n","\\frac{\\partial s}{\\partial x} = \\frac{\\partial s}{\\partial c} \\frac{\\partial c}{\\partial b} \\frac{\\partial b}{\\partial a} \\frac{\\partial a}{\\partial x}\n","$$"]},{"cell_type":"code","metadata":{"id":"7cJQf_nZnDFU","colab_type":"code","outputId":"871d1f50-d2df-403c-ef85-ce5b16ee9a09","executionInfo":{"status":"ok","timestamp":1589097224977,"user_tz":-120,"elapsed":516,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["def grad_sigmoid_manual(x):\n","    \"\"\"Implements the gradient of the logistic sigmoid function \n","    $\\sigma(x) = 1 / (1 + e^{-x})$ using staged computation\n","    \"\"\"\n","    # Forward pass, keeping track of intermediate values for use in the \n","    # backward pass\n","    a = -x         # -x in denominator\n","    b = np.exp(a)  # e^{-x} in denominator\n","    c = 1 + b      # 1 + e^{-x} in denominator\n","    s = 1.0 / c    # Final result, 1.0 / (1 + e^{-x})\n","    \n","    # Backward pass\n","    dsdc = (-1.0 / (c**2))\n","    dsdb = dsdc * 1\n","    dsda = dsdb * np.exp(a)\n","    dsdx = dsda * (-1)\n","    \n","    return dsdx\n","\n","def sigmoid(x):\n","    y = 1.0 / (1.0 + np.exp(-x))\n","    return y\n","\n","# Instead of writing grad_sigmoid_manual manually, we can use \n","# Autograd's grad function:\n","grad_sigmoid_automatic = grad(sigmoid)\n","\n","# Compare the results of manual and automatic gradient functions:\n","print(f'Autograd gradient:  {grad_sigmoid_automatic(2.0)}')\n","print(f'Manual gradient:    {grad_sigmoid_manual(2.0)}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Autograd gradient:  0.1049935854035065\n","Manual gradient:    0.1049935854035065\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aiudVIRanDF0","colab_type":"text"},"source":["# Example"]},{"cell_type":"markdown","metadata":{"id":"T75zcxhl09uU","colab_type":"text"},"source":["## Linear Regression with Autograd\n","\n","\n","The next section of the notebook shows an example of using Autograd in the context of **1-D linear regression** by gradient descent.\n","\n","We try to fit a model to a function $y = wx + b$\n","\n","### Review\n","\n","We are given a set of data points $\\{ (x_1, t_1), (x_2, t_2), \\dots, (x_N, t_N) \\}$, where each point $(x_i, t_i)$ consists of an *input value* $x_i$ and a *target value* $t_i$. \n","\n","The **model** we use is:\n","$$\n","y_i = wx_i + b\n","$$\n","\n","We want each predicted value $y_i$ to be close to the ground truth value $t_i$. In linear regression, we use squared error to quantify the disagreement between $y_i$ and $t_i$. The **loss function** for a single example is:\n","$$\n","\\mathcal{L}(y_i,t_i) = \\frac{1}{2} (y_i - t_i)^2\n","$$\n","\n","The **cost function** is the loss averaged over all the training examples:\n","$$\n","\\mathcal{C}(w,b) = \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}(y_i, t_i) = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{2} \\left(wx_i + b - t_i \\right)^2\n","$$"]},{"cell_type":"code","metadata":{"id":"E4hK2MOAnDF3","colab_type":"code","colab":{}},"source":["import autograd.numpy as np # Import wrapped NumPy from Autograd\n","from autograd import grad # To compute gradients\n","\n","import matplotlib.pyplot as plt # Most common plotting / data visualization tool in Python"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPfdASFQnDF5","colab_type":"text"},"source":["## Generate Synthetic Data"]},{"cell_type":"markdown","metadata":{"id":"S45qybWOnDF6","colab_type":"text"},"source":["We generate a synthetic dataset $\\{ (x_i, t_i) \\}$ by first taking the $x_i$ to be linearly spaced in the range $[0, 1]$ and generating the corresponding value of $t_i$ using the following equation (where $w = 2$ and $b=0.5$):\n","$$\n","t_i = 2 x_i + 0.5 + \\epsilon\n","$$\n","\n","Here, $\\epsilon \\sim \\mathcal{N}(0, 0.01)$ (that is, $\\epsilon$ is drawn from a Gaussian distribution with mean 0 and variance 0.01). This introduces some random fluctuation in the data, to mimic real data that has an underlying regularity, but for which individual observations are corrupted by random noise."]},{"cell_type":"code","metadata":{"id":"mDK6fwdpnDF6","colab_type":"code","outputId":"a5e0df51-c3ae-4bb8-fc2d-8cc6f6eedfb0","executionInfo":{"status":"ok","timestamp":1589097306698,"user_tz":-120,"elapsed":689,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["# In our synthetic data, we have w = 2 and b = 0.5\n","N = 100 # Number of training data points\n","x = np.random.uniform(size=(N,))\n","eps = np.random.normal(size=(len(x),), scale=0.1)\n","t = 2.0 * x + 0.5 + eps\n","plt.plot(x, t, 'r.')"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f543b7d0550>]"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ByBaU87AnDGF","colab_type":"code","outputId":"28b1380f-27d4-412b-d73e-229a417411fb","executionInfo":{"status":"ok","timestamp":1589097509120,"user_tz":-120,"elapsed":1261,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Initialize random parameters\n","w = np.random.normal(0, 1)\n","b = np.random.normal(0, 1)\n","params = { 'w': w, 'b': b } # One option: aggregate parameters in a dictionary\n","\n","def cost(params):\n","    y = params['w'] * x + params['b']\n","    return (1 / N) * np.sum(0.5 * np.square(y - t))\n","\n","# Find the gradient of the cost function using Autograd\n","grad_cost = grad(cost) \n","\n","num_epochs = 2000  # Number of epochs of training\n","alpha = 0.025       # Learning rate\n","\n","for i in range(num_epochs):\n","    # Evaluate the gradient of the current parameters stored in params\n","    cost_params = grad_cost(params)\n","    \n","    # Gradient Descent step\n","    # Update parameters w and b\n","    params['w'] = params['w'] - alpha * cost_params['w']\n","    params['b'] = params['b'] - alpha * cost_params['b']\n","\n","print(params)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["{'w': 1.926380013972517, 'b': 0.5288309549899681}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PNUXTgQNnDGH","colab_type":"code","outputId":"46351036-5b2d-41e5-f0e8-4fb86ac07a33","executionInfo":{"status":"ok","timestamp":1589097522933,"user_tz":-120,"elapsed":502,"user":{"displayName":"Marc Fischer","photoUrl":"","userId":"13738362924469851898"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["# Plot the training data again, together with the line defined by y = wx + b\n","# where w and b are our final learned parameters\n","plt.plot(x, t, 'r.')\n","plt.plot([0, 1], [params['b'], params['w'] + params['b']], 'b-')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f543b79d7f0>]"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}