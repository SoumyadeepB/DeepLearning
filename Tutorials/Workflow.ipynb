{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"2005_intro_nb_workflow.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb","timestamp":1588971187011}],"private_outputs":true,"collapsed_sections":["g_nWetWWd_ns","pZJ3uY9O17VN","62O049dYKEsd","yDIfqwDn2ld4","n4EKOpw9mObL","77AsVr1GGtBP","ohbSnA79mcJV","h_Y4uC1R1B55","NTEvpBK9f8kj","4LfnJjm0Bm0B","Em5dzSUOtLRP","znmy4l8ntMvW","oeYV6mKnJGMr","SnsumiP6eRYL"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g_nWetWWd_ns"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"both","colab_type":"code","id":"2pHVBk_seED1","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"both","colab_type":"code","id":"N_fMsQ-N8I7j","colab":{}},"source":["#@title MIT License\n","#\n","# Copyright (c) 2017 François Chollet\n","#\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8Byow2J6LaPl"},"source":["# Introduction to TensorFlow\n","# Notebook - Workflow\n","\n","*Disclosure: This notebook is an adaptation of official TensorFlow tutorials.*"]},{"cell_type":"markdown","metadata":{"id":"NtMlu2YuNTa_","colab_type":"text"},"source":["This notebook is covering multiple aspects of common Deep Learning workflows:\n","\n","*   Save and load Keras models\n","*   Dataset Management\n","*   AutGraph in TensorFlow 2.0\n","\n","More information of each introduced topic can be found on the TensorFlow website."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pZJ3uY9O17VN"},"source":["# Save and load Keras models"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mBdde4YJeJKF"},"source":["Model progress can be saved during—and after—training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\n","\n","* code to create the model, and\n","* the trained weights, or parameters, for the model\n","\n","Sharing this data helps others understand how the model works and try it themselves with new data.\n","\n","Caution: Be careful with untrusted code—TensorFlow models are code. See [Using TensorFlow Securely](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for details.\n","\n","### Options\n","\n","There are different ways to save TensorFlow models—depending on the API you're using. This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow. For other approaches, see the TensorFlow  [Save and Restore](https://www.tensorflow.org/guide/saved_model) guide or [Saving in eager](https://www.tensorflow.org/guide/eager#object-based_saving)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xCUREq7WXgvg"},"source":["## Setup\n","\n","### Installs and imports\n","Install and import TensorFlow and dependencies:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RzIOVSdnMYyO","colab":{}},"source":["!pip install pyyaml h5py  # Package dependencies to save models in HDF5 format"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7Nm7Tyb-gRt-","colab":{}},"source":["import os\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","print(tf.version.VERSION)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SbGsznErXWt6"},"source":["### Get an example dataset\n","\n","To demonstrate how to save and load weights, you'll use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). To speed up these runs, use the first 2000 examples:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9rGfFwE9XVwz","colab":{}},"source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","train_labels = train_labels[:2000]\n","test_labels = test_labels[:2000]\n","\n","train_images = train_images[:2000].reshape(-1, 28 * 28) / 255.0\n","test_images = test_images[:2000].reshape(-1, 28 * 28) / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"anG3iVoXyZGI"},"source":["### Define a model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wynsOBfby0Pa"},"source":["Start by building a simple sequential model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0HZbJIjxyX1S","colab":{}},"source":["# Define a simple sequential model\n","def create_model():\n","  model = tf.keras.models.Sequential([\n","    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(10)\n","  ])\n","\n","  model.compile(optimizer='adam',\n","                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                metrics=['accuracy'])\n","\n","  return model\n","\n","# Create a basic model instance\n","model = create_model()\n","\n","# Display the model's architecture\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"soDE0W_KH8rG"},"source":["## Save checkpoints during training"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mRyd5qQQIXZm"},"source":["You can use a trained model without having to retrain it, or pick-up training where you left off—in case the training process was interrupted. The `tf.keras.callbacks.ModelCheckpoint` callback allows to continually save the model both *during* and at *the end* of training.\n","\n","### Checkpoint callback usage\n","\n","Create a `tf.keras.callbacks.ModelCheckpoint` callback that saves weights only during training:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IFPuhwntH8VH","colab":{}},"source":["checkpoint_path = \"training_1/cp.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)\n","\n","# Train the model with the new callback\n","model.fit(train_images, \n","          train_labels,  \n","          epochs=10,\n","          validation_data=(test_images,test_labels),\n","          callbacks=[cp_callback])  # Pass callback to training\n","\n","# This may generate warnings related to saving the state of the optimizer.\n","# These warnings (and similar warnings throughout this notebook)\n","# are in place to discourage outdated usage, and can be ignored."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rlM-sgyJO084"},"source":["This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gXG5FVKFOVQ3","colab":{}},"source":["!ls {checkpoint_dir}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wlRN_f56Pqa9"},"source":["Create a new, untrained model. When restoring a model from weights-only, you must have a model with the same architecture as the original model. Since it's the same model architecture, you can share weights despite that it's a different *instance* of the model.\n","\n","Now rebuild a fresh, untrained model, and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fp5gbuiaPqCT","colab":{}},"source":["# Create a basic model instance\n","model = create_model()\n","\n","# Evaluate the model\n","loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1DTKpZssRSo3"},"source":["Then load the weights from the checkpoint and re-evaluate:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2IZxbwiRRSD2","colab":{}},"source":["# Loads the weights\n","model.load_weights(checkpoint_path)\n","\n","# Re-evaluate the model\n","loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bpAbKkAyVPV8"},"source":["### Checkpoint callback options\n","\n","The callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n","\n","Train a new model, and save uniquely named checkpoints once every five epochs:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mQF_dlgIVOvq","colab":{}},"source":["# Include the epoch in the file name (uses `str.format`)\n","checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create a callback that saves the model's weights every 5 epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1, \n","    save_weights_only=True,\n","    # save_best_only=True  # you might also consider saving only the best model\n","    save_freq='epoch')  # save a checkpoint every epoch.\n","\n","# Create a new model instance\n","model = create_model()\n","\n","# Save the weights using the `checkpoint_path` format\n","model.save_weights(checkpoint_path.format(epoch=0))\n","\n","# Train the model with the new callback\n","model.fit(train_images, \n","          train_labels,\n","          epochs=50, \n","          callbacks=[cp_callback],\n","          validation_data=(test_images,test_labels),\n","          verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1zFrKTjjavWI"},"source":["Now, look at the resulting checkpoints and choose the latest one:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p64q3-V4sXt0","colab":{}},"source":["!ls {checkpoint_dir}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1AN_fnuyR41H","colab":{}},"source":["latest = tf.train.latest_checkpoint(checkpoint_dir)\n","latest"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zk2ciGbKg561"},"source":["Note: the default tensorflow format only saves the 5 most recent checkpoints.\n","\n","To test, reset the model and load the latest checkpoint:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3M04jyK-H3QK","colab":{}},"source":["# Create a new model instance\n","model = create_model()\n","\n","# Load the previously saved weights\n","model.load_weights(latest)\n","\n","# Re-evaluate the model\n","loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c2OxsJOTHxia"},"source":["## What are these files?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JtdYhvWnH2ib"},"source":["The above code stores the weights to a collection of [checkpoint](https://www.tensorflow.org/guide/saved_model#save_and_restore_variables)-formatted files that contain only the trained weights in a binary format. Checkpoints contain:\n","* One or more shards that contain your model's weights.\n","* An index file that indicates which weights are stored in a which shard.\n","\n","If you are only training a model on a single machine, you'll have one shard with the suffix: `.data-00000-of-00001`"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S_FA-ZvxuXQV"},"source":["## Manually save weights\n","\n","You saw how to load the weights into a model. Manually saving them is just as simple with the `Model.save_weights` method. By default, `tf.keras`—and `save_weights` in particular—uses the TensorFlow [checkpoint](../../guide/checkpoint.ipynb) format with a `.ckpt` extension (saving in [HDF5](https://js.tensorflow.org/tutorials/import-keras.html) with a `.h5` extension is covered in the [Save and serialize models](../../guide/keras/save_and_serialize#weights-only_saving_in_savedmodel_format) guide):"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R7W5plyZ-u9X","colab":{}},"source":["# Save the weights\n","model.save_weights('./checkpoints/my_checkpoint')\n","\n","# Create a new model instance\n","model = create_model()\n","\n","# Restore the weights\n","model.load_weights('./checkpoints/my_checkpoint')\n","\n","# Evaluate the model\n","loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XwDdhWIp0Vo1","colab_type":"text"},"source":["Note, that the above code might produce warnings. This happens, if the checkpoint contains parameter values, that are not used by the instantiated model or if not all variables of the instantiated model have a corresponding parameter within the checkpoint. Often times, this is the case for internal parameter values of the optimizer."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kOGlxPRBEvV1"},"source":["## Save the entire model\n","\n","Call [`model.save`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save) to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n","\n","Entire model can be saved in two different file formats (`SavedModel` and `HDF5`). It is to be noted that TensorFlow `SavedModel` format is the default file format in TF2.x. However, model can be saved in `HDF5` format. More details on saving entire model in the two file formats is described below.\n","\n","Saving a fully-functional model is very useful—you can load them in TensorFlow.js ([Saved Model](https://www.tensorflow.org/js/tutorials/conversion/import_saved_model), [HDF5](https://www.tensorflow.org/js/tutorials/conversion/import_keras)) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite ([Saved Model](https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_), [HDF5](https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_))\n","\n","\\*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the **Saving custom objects** section below "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kPyhgcoVzqUB"},"source":["### SavedModel format"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LtcN4VIb7JkK"},"source":["The SavedModel format is another way to serialize models. Models saved in this format can be restored using `tf.keras.models.load_model` and are compatible with TensorFlow Serving. The [SavedModel guide](https://www.tensorflow.org/guide/saved_model) goes into detail about how to serve/inspect the SavedModel. The section below illustrates the steps to saving and restoring the model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sI1YvCDFzpl3","colab":{}},"source":["# Create and train a new model instance.\n","model = create_model()\n","model.fit(train_images, train_labels, epochs=5)\n","\n","# Save the entire model as a SavedModel.\n","!mkdir -p saved_model\n","model.save('saved_model/my_model') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iUvT_3qE8hV5"},"source":["The SavedModel format is a directory containing a protobuf binary and a Tensorflow checkpoint. Inspect the saved model directory:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sq8fPglI1RWA","colab":{}},"source":["# my_model directory\n","!ls saved_model\n","\n","# Contains an assets folder, saved_model.pb, and variables folder.\n","!ls saved_model/my_model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B7qfpvpY9HCe"},"source":["Reload a fresh Keras model from the saved model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0YofwHdN0pxa","colab":{}},"source":["new_model = tf.keras.models.load_model('saved_model/my_model')\n","\n","# Check its architecture\n","new_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uWwgNaz19TH2"},"source":["The restored model is compiled with the same arguments as the original model. Try running evaluate and predict with the loaded model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yh5Mu0yOgE5J","colab":{}},"source":["# Evaluate the restored model\n","loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n","\n","print(new_model.predict(test_images).shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SkGwf-50zLNn"},"source":["### HDF5 format\n","\n","Keras provides a basic save format using the [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m2dkmJVCGUia","colab":{}},"source":["# Create and train a new model instance.\n","model = create_model()\n","model.fit(train_images, train_labels, epochs=5)\n","\n","# Save the entire model to a HDF5 file.\n","# The '.h5' extension indicates that the model should be saved to HDF5.\n","model.save('my_model.h5') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GWmttMOqS68S"},"source":["Now, recreate the model from that file:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5NDMO_7kS6Do","colab":{}},"source":["# Recreate the exact same model, including its weights and the optimizer\n","new_model = tf.keras.models.load_model('my_model.h5')\n","\n","# Show the model architecture\n","new_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JXQpbTicTBwt"},"source":["Check its accuracy:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jwEaj9DnTCVA","colab":{}},"source":["loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dGXqd4wWJl8O"},"source":["Keras saves models by inspecting the architecture. This technique saves everything:\n","\n","* The weight values\n","* The model's architecture\n","* The model's training configuration(what you passed to compile)\n","* The optimizer and its state, if any (this enables you to restart training where you left)\n","\n","Keras is not able to save the `v1.x` optimizers (from `tf.compat.v1.train`) since they aren't compatible with checkpoints. For v1.x optimizers, you need to re-compile the model after loading—losing the state of the optimizer.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kAUKJQyGqTNH"},"source":["### Saving custom objects\n","\n","If you are using the SavedModel format, you can skip this section. The key difference between HDF5 and SavedModel is that HDF5 uses object configs to save the model architecture, while SavedModel saves the execution graph. Thus, SavedModels are able to save custom objects like subclassed models and custom layers without requiring the orginal code.\n","\n","To save custom objects to HDF5, you must do the following:\n","\n","1. Define a `get_config` method in your object, and optionally a `from_config` classmethod.\n","  * `get_config(self)` returns a JSON-serializable dictionary of parameters needed to recreate the object.\n","  * `from_config(cls, config)` uses the returned config from `get_config` to create a new object. By default, this function will use the config as initialization kwargs (`return cls(**config)`).\n","2. Pass the object to the `custom_objects` argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g. `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`\n","\n","See the [Writing layers and models from scratch](https://www.tensorflow.org/guide/keras/custom_layers_and_models) tutorial for examples of custom objects and `get_config`.\n"]},{"cell_type":"markdown","metadata":{"id":"62O049dYKEsd","colab_type":"text"},"source":["# Dataset Management"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6XvCUmCEd4Dm"},"source":["The following chapter covers **Dataset API** and **TensorFlow Datasets**."]},{"cell_type":"code","metadata":{"id":"kdHDhD2jEt9T","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qk-ZVuDDCr2S","colab_type":"text"},"source":["##Dataset API\n","TensorFlow provides a rich `tf.data.Dataset` API which allows you to easily manage complex pipeline operations."]},{"cell_type":"markdown","metadata":{"id":"E6TQvivpJDYV","colab_type":"text"},"source":["The Dataset object is a Python iterable. This makes it possible to consume its elements using a for loop.\n"]},{"cell_type":"code","metadata":{"id":"ZKDMJ8OCJFSm","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.range(10)\n","for elem in dataset:\n","  print(elem.numpy())  # prints 0, 1, ..., 9"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r5BnZnMaXoh9","colab_type":"text"},"source":["###Dataset manipulation\n","\n","Datasets provide methods, that allow the manipulation of elements. As such the elements can be subject to arbitrary transformations."]},{"cell_type":"code","metadata":{"id":"1Tv4VhXcXqkF","colab_type":"code","colab":{}},"source":["dummy_data = tf.random.uniform([4])\n","print('Dummy data: ', dummy_data.numpy())\n","\n","dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4]))\n","dataset1 = dataset1.map(lambda x: x*x)\n","\n","dataset2 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4]))\n","dataset2 = dataset2.filter(lambda x: x > 0.5)\n","\n","dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n","dataset3 = dataset3.map(lambda x, y: x+y)\n","\n","print(\"\\n dataset 1\\n\")\n","for elem in dataset1:\n","  print(elem.numpy())\n","\n","print(\"\\n dataset 2\\n\")\n","for elem in dataset2:\n","  print(elem.numpy())\n","  \n","print(\"\\n dataset 3\\n\")\n","for elem in dataset3:\n","  print(elem.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBOqj200Dz4-","colab_type":"text"},"source":["------"]},{"cell_type":"markdown","metadata":{"id":"aURnKhmKCoBR","colab_type":"text"},"source":["##TensorFlow Datasets\n","\n","TensorFlow Datasets provides a collection of datasets ready to use with TensorFlow. It handles downloading and preparing the data and constructing a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_7hshda5eaGL"},"source":["###Installation\n","\n","`pip install tensorflow-datasets`\n","\n","Note that `tensorflow-datasets` expects you to have TensorFlow already installed, and currently depends on `tensorflow` (or `tensorflow-gpu`) >= `1.13.0`."]},{"cell_type":"code","metadata":{"cellView":"both","colab_type":"code","id":"boeZp0sYbO41","colab":{}},"source":["!pip install tensorflow-datasets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g6Jp3fNm3ueh","colab_type":"text"},"source":["###Import required modules\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TTBSvHcSLBzc","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","import tensorflow_datasets as tfds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VZZyuO13fPvk"},"source":["###List the available datasets\n","\n","Each dataset is implemented as a [`tfds.core.DatasetBuilder`](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder) and you can list all available builders with `tfds.list_builders()`.\n","\n","You can see all the datasets with additional documentation on the [datasets documentation page](https://github.com/tensorflow/datasets/blob/master/docs/datasets.md)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FAvbSVzjLCIb","colab":{}},"source":["tfds.list_builders()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VjI6VgOBf0v0"},"source":["###`tfds.load`: A dataset in one line\n","\n","[`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) is a convenience method that's the simplest way to build and load and `tf.data.Dataset`. Below, we load the MNIST training data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dCou80mnLLPV","colab":{}},"source":["ds, info = tfds.load(name=\"mnist\", with_info=True)  # also fetch dataset info\n","mnist_train = ds[\"train\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDQsr5U04YJO","colab_type":"text"},"source":["**Note:** The dataset can also be called directly by passing a split argument, i.e.  \n"," `mnist_train = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)`"]},{"cell_type":"markdown","metadata":{"id":"6qFsQJP66imT","colab_type":"text"},"source":["`tfds` returns a dictionary containing a \"train\" and a \"test\" `tf.data.Dataset` with respective keys.  \n","`info` contains furtherl information on the fetched dataset.\n"]},{"cell_type":"code","metadata":{"id":"ex9RdF546TD8","colab_type":"code","colab":{}},"source":["print(\"tfds type: \", type(ds), \"\\n\")\n","\n","print(\"tfds dictionary: \", ds, \"\\n\")\n","\n","print(\"train dataset type: \", type(mnist_train), \"\\n\")\n","\n","print(\"tfds info: \", info)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u-GAxR79hGTr"},"source":["### Feature dictionaries\n","\n","All `tfds` datasets contain feature dictionaries mapping feature names to Tensor values. A typical dataset, like MNIST, will have 2 keys: `\"image\"` and `\"label\"`. Below we inspect a single example."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YHE21nkHLrER","colab":{}},"source":["mnist_example, = mnist_train.take(1)\n","image, label = mnist_example[\"image\"], mnist_example[\"label\"]\n","\n","plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap(\"gray\"))\n","print(f\"Label: {label.numpy()}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EW-kEK_mhbhy"},"source":["### DatasetBuilder\n","\n","`tfds.load` is really a thin conveninence wrapper around `DatasetBuilder`. We can accomplish the same as above directly with the MNIST `DatasetBuilder`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9FDDJXmBhpQ4","colab":{}},"source":["mnist_builder = tfds.builder(\"mnist\")\n","mnist_builder.download_and_prepare()\n","mnist_train = mnist_builder.as_dataset(split=tfds.Split.TRAIN)\n","mnist_train"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uczpNuc_A7wE"},"source":["### DatasetInfo\n","\n","After generation, the builder contains useful information on the dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mSamfFznA9Ph","colab":{}},"source":["info = mnist_builder.info\n","print(info)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cspsneov2VbC","colab_type":"text"},"source":["`DatasetInfo` also contains useful information about the features:"]},{"cell_type":"code","metadata":{"id":"u1wL14QH2TW1","colab_type":"code","colab":{}},"source":["print(info.features)\n","print(info.features[\"label\"].num_classes)\n","print(info.features[\"label\"].names)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xbrm0WBmBLEI"},"source":["You can also load the `DatasetInfo` directly with `tfds.load` using `with_info=True`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tvZYujQwBL7B","colab":{}},"source":["dataset, info = tfds.load(\"mnist\", split=\"test\", with_info=True)\n","print(info)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7tlVOAzLlKqc"},"source":["### Input pipelines\n","\n","Once you have a `tf.data.Dataset` object, it's simple to define the rest of an input pipeline suitable for model training by using the [`tf.data` API](https://www.tensorflow.org/guide/datasets).\n","\n","Here we'll repeat the dataset so that we have an infinite stream of shuffled examples. After the augmentation batches of 32 are created."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9OQZqGZMlSE8","colab":{}},"source":["mnist_train_shuffled = mnist_train.repeat().shuffle(1024)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24n5tWoKHD2w","colab_type":"text"},"source":["### Augmentation\n","\n","The dataset API makes it easy to integrate mapping functions. As such, pre-processing steps (e.g. data parsing, augmentation, ...) can be included within a dataset.map() call to apply transformations on the fly.\n","\n","Add an augmentation transformation to the dataset pipeline.\n"]},{"cell_type":"code","metadata":{"id":"vnQGAMP-XbrH","colab_type":"code","colab":{}},"source":["def augmentation(input, HEIGHT=28, WIDTH=28, NUM_CHANNELS=1):\n","    print(input)\n","    x = tf.image.per_image_standardization(input['image'])  # normalize image\n","    x = tf.image.resize_with_crop_or_pad(x, HEIGHT + 8, WIDTH + 8)  # resize image\n","    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])  # random crop\n","    x = tf.image.random_flip_left_right(x)  # random flip\n","    # Be careful to select only those operations, that apply to your dataset.\n","    # Flipping might not be a sensible choice for a MNIST classification\n","    return {'image': x, 'label': input['label']}\n","  \n","mnist_train_aug = mnist_train_shuffled.map(augmentation)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLJbpGoLGryP","colab_type":"code","colab":{}},"source":["# prefetch will enable the input pipeline to asynchronously fetch batches while\n","# your model is training.\n","mnist_train_batched = mnist_train_aug.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","# Now you could loop over batches of the dataset and train\n","# for batch in mnist_train:\n","#   ..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyf-6HdCIeY-","colab_type":"code","colab":{}},"source":["mnist_example, = mnist_train_batched.take(1)\n","image, label = mnist_example[\"image\"], mnist_example[\"label\"]\n","\n","plt.imshow(image.numpy()[0, :, :, 0].astype(np.float32), cmap=plt.get_cmap(\"gray\"))\n","print(f\"Label: {label.numpy()}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDIfqwDn2ld4","colab_type":"text"},"source":["# AutoGraph in TensorFlow 2.0"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CydFK2CL7ZHA"},"source":["TF 2.0 brings together the ease of eager execution and the power of TF 1.0. At the center of this merger is `tf.function`, which allows you to transform a subset of Python syntax into portable, high-performance TensorFlow graphs.\n","\n","A cool new feature of `tf.function` is AutoGraph, which lets you write graph code using natural Python syntax. For a list of the Python features that you can use with AutoGraph, see [AutoGraph Capabilities and Limitations](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md). For more details about `tf.function`, see the [TF 2.0: Functions, not Sessions](https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md). For more details about AutoGraph, see `tf.autograph`.\n","\n","This tutorial will walk you through the basic features of `tf.function` and AutoGraph."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"n4EKOpw9mObL"},"source":["## Setup\n","\n","Import TensorFlow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mT7meGqrZTz9","colab":{}},"source":["!pip install tensorflow\n","import tensorflow as tf\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"77AsVr1GGtBP"},"source":["## The `tf.function` decorator\n","\n","When you annotate a function with `tf.function`, you can still call it like any other function. But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FhIg7-z6HNWj","colab":{}},"source":["@tf.function\n","def simple_nn_layer(x, y):\n","  return tf.nn.relu(tf.matmul(x, y))\n","\n","\n","x = tf.random.uniform((3, 3))\n","y = tf.random.uniform((3, 3))\n","\n","simple_nn_layer(x, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U-LAE4pMNR9g"},"source":["If we examine the result of the annotation, we can see that it's a special callable that handles all interactions with the TensorFlow runtime."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q4t2iuS7Nqc0","colab":{}},"source":["simple_nn_layer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DqeefLGNXjZQ"},"source":["If your code uses multiple functions, you don't need to annotate them all - any functions called from an annotated function will also run in graph mode."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3VGF7tlVXiZY","colab":{}},"source":["def linear_layer(x):\n","  return 2 * x + 1\n","\n","\n","@tf.function\n","def deep_net(x):\n","  return tf.nn.relu(linear_layer(x))\n","\n","\n","deep_net(tf.constant((1, 2, 3)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yQvg6ZSKWyqE"},"source":["Functions can be faster than eager code, for graphs with many small ops. The performance difference will increase with the number of ops included. But for graphs with a few expensive ops (like convolutions), you may not see much speedup. \n"]},{"cell_type":"code","metadata":{"id":"QhFvK6h7FfqF","colab_type":"code","colab":{}},"source":["# import timeit to measure the execution time\n","import timeit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0EL6lVwEWuFo","colab":{}},"source":["\n","conv_layer = tf.keras.layers.Conv2D(100, 3)\n","\n","@tf.function\n","def conv_fn(image):\n","  return conv_layer(image)\n","\n","image = tf.zeros([1, 200, 200, 100])\n","# warm up\n","conv_layer(image); conv_fn(image)\n","print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n","print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L4zj-jpH0jKH","colab":{}},"source":["lstm_cell = tf.keras.layers.LSTMCell(10)\n","\n","@tf.function\n","def lstm_fn(input, state):\n","  return lstm_cell(input, state)\n","\n","input_lstm = tf.zeros([10, 10])\n","state_lstm = [tf.zeros([10, 10])] * 2\n","# warm up\n","lstm_cell(input_lstm, state_lstm); lstm_fn(input_lstm, state_lstm)\n","print(\"Eager lstm:\", timeit.timeit(lambda: lstm_cell(input_lstm, state_lstm), number=10))\n","print(\"Function lstm:\", timeit.timeit(lambda: lstm_fn(input_lstm, state_lstm), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ohbSnA79mcJV"},"source":["## Use Python control flow\n","\n","When using data-dependent control flow inside `tf.function`, you can use Python control flow statements and AutoGraph will convert them into appropriate TensorFlow ops. For example, `if` statements will be converted into `tf.cond()` if they depend on a `Tensor`.\n","\n","In the example below, `x` is a `Tensor` but the `if` statement works as expected:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aA3gOodCBkOw","colab":{}},"source":["@tf.function\n","def square_if_positive(x):\n","  if x > 0:\n","    x = x * x\n","  else:\n","    x = 0\n","  return x\n","\n","\n","print(f'square_if_positive(2) = {square_if_positive(tf.constant(2))}')\n","print(f'square_if_positive(-2) = {square_if_positive(tf.constant(-2))}')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m-jWmsCmByyw"},"source":["AutoGraph supports common Python statements like `while`, `for`, `if`, `break`, `continue` and `return`, with support for nesting. That means you can use `Tensor` expressions in the condition of `while` and `if` statements, or iterate over a `Tensor` in a `for` loop."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"toxKBOXbB1ro","colab":{}},"source":["@tf.function\n","def sum_even_fn(items):\n","  s = 0\n","  for c in items:\n","    if c % 2 > 0:\n","      continue\n","    s += c\n","  return s\n","\n","sum_even_fn(tf.constant(tf.range(500)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AtDaLrbySw4j"},"source":["AutoGraph also provides a low-level API for advanced users. For example we can use it to have a look at the generated code."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aRsde3x_SjTQ","colab":{}},"source":["print(tf.autograph.to_code(sum_even_fn.python_function))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rvJXCfk8VkLf"},"source":["Let's compare this control flow for Python vs TensorFlow Graph code. For simple functions, it might not be a good idea to introduce a computation graph overhead."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h-Z87IJqVlKl","colab":{}},"source":["def sum_even(items):\n","  s = 0\n","  for c in items:\n","    if c % 2 > 0:\n","      continue\n","    s += c\n","  return s\n","\n","\n","sum_even(range(500))\n","\n","# warm up\n","in_sum = list(range(500)); sum_even(in_sum)\n","in_sum_fn = tf.constant(tf.range(500)); sum_even_fn(in_sum_fn)\n","print(f\"Results: Python code: {sum_even(in_sum)}, TF code: {sum_even_fn(in_sum_fn).numpy()}\")\n","print(\"Python:  \", timeit.timeit(lambda: sum_even(in_sum), number=10))\n","print(\"TF graph:\", timeit.timeit(lambda: sum_even_fn(in_sum_fn), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h_Y4uC1R1B55"},"source":["## Keras and AutoGraph\n","\n","AutoGraph is available by default in non-dynamic Keras models. For more information, see `tf.keras`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cR6mpLKP1HLe","colab":{}},"source":["class CustomModel(tf.keras.models.Model):\n","\n","  @tf.function\n","  def call(self, input_data):\n","    if tf.reduce_mean(input_data) > 0:\n","      return input_data\n","    else:\n","      return input_data // 2\n","\n","\n","model = CustomModel()\n","\n","model(tf.constant([-2, -4]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NTEvpBK9f8kj"},"source":["## Side effects\n","\n","Tensors defined out of scope, can be manipulated within a function. Just like in eager mode, you can use operations with side effects, like `tf.assign` or `tf.print` normally inside `tf.function`, and it will insert the necessary control dependencies to ensure they execute in order."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-Wd6i8S9gcuC","colab":{}},"source":["v = tf.Variable(5)\n","print(v.numpy())\n","\n","@tf.function\n","def find_next_odd():\n","  v.assign(v + 1)\n","  if tf.equal(v % 2, 0):\n","    v.assign(v + 1)\n","\n","\n","find_next_odd()\n","print(v.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4LfnJjm0Bm0B"},"source":["## Example: training a simple model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Em5dzSUOtLRP"},"source":["### Download data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xqoxumv0ssQW","colab":{}},"source":["def prepare_mnist_features_and_labels(x, y):\n","  x = tf.cast(x, tf.float32) / 255.0\n","  y = tf.cast(y, tf.int64)\n","  return x, y\n","\n","def mnist_dataset():\n","  (x, y), _ = tf.keras.datasets.mnist.load_data()\n","  ds = tf.data.Dataset.from_tensor_slices((x, y))\n","  ds = ds.map(prepare_mnist_features_and_labels)\n","  ds = ds.take(20000).shuffle(20000).batch(100)\n","  return ds\n","\n","train_dataset = mnist_dataset()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"znmy4l8ntMvW"},"source":["### Define the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ltxyJVWTqNAO","colab":{}},"source":["model = tf.keras.Sequential((\n","    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n","    tf.keras.layers.Dense(100, activation='relu'),\n","    tf.keras.layers.Dense(100, activation='relu'),\n","    tf.keras.layers.Dense(10)))\n","model.build()\n","optimizer = tf.keras.optimizers.Adam()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oeYV6mKnJGMr"},"source":["### Define the training loop\n","\n","For some models, that consist of multiple networks, such as GANs, it can be crucial to wrap the training step with @tf.function."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3xtg_MMhJETd","colab":{}},"source":["compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","@tf.function\n","def train_one_step(model, optimizer, x, y):\n","  with tf.GradientTape() as tape:\n","    logits = model(x)\n","    loss = compute_loss(y, logits)\n","\n","  grads = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","  compute_accuracy(y, logits)\n","  return loss\n","\n","\n","def train(model, optimizer):\n","  train_ds = mnist_dataset()\n","  step = 0\n","  loss = 0.0\n","  accuracy = 0.0\n","  for x, y in train_ds:\n","    step += 1\n","    loss = train_one_step(model, optimizer, x, y)\n","    if tf.equal(step % 10, 0):\n","      tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n","  return step, loss, accuracy\n","\n","step, loss, accuracy = train(model, optimizer)\n","print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SnsumiP6eRYL"},"source":["## Batching\n","\n","In real applications batching is essential for performance. The best code to convert to AutoGraph is code where the control flow is decided at the _batch_ level. If making decisions at the individual _example_ level, try to use batch APIs to maintain performance.\n","\n","For example, if you have the following code in Python:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"t31QoERiNccJ","colab":{}},"source":["def square_if_positive(x):\n","  return [i ** 2 if i > 0 else i for i in x]\n","\n","\n","print(square_if_positive(range(-5, 5)))\n","print(timeit.timeit(lambda: square_if_positive(range(-5, 5)), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kSeEJ76uNgwD"},"source":["You may be tempted to write it in TensorFlow as such (and this would work!):\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RqR8WzSzNf87","colab":{}},"source":["@tf.function\n","def square_if_positive_naive(x):\n","  result = tf.TensorArray(tf.int32, size=x.shape[0])\n","  for i in tf.range(x.shape[0]):\n","    if x[i] > 0:\n","      result = result.write(i, x[i] ** 2)\n","    else:\n","      result = result.write(i, x[i])\n","  return result.stack()\n","\n","\n","print(square_if_positive_naive(tf.range(-5, 5)))\n","print(timeit.timeit(lambda: square_if_positive_naive(tf.range(-5, 5)), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gTcyWXVGN3gS"},"source":["But in this case, it turns out you can write the following:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VO2f6x-lNfVj","colab":{}},"source":["def square_if_positive_vectorized(x):\n","  return tf.where(x > 0, x ** 2, x)\n","\n","\n","print(square_if_positive_vectorized(tf.range(-5, 5)))\n","print(timeit.timeit(lambda: square_if_positive_vectorized(tf.range(-5, 5)), number=10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6G_Ur1JB43Nt","colab_type":"text"},"source":["For more information have a look at the tutorial on [performance with tf.function](https://www.tensorflow.org/guide/function?hl=lt)"]}]}